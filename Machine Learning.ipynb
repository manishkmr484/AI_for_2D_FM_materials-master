{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rational-divide",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "### Sheth Riya Nimish\n",
    "### A0176880R\n",
    "e0235287@u.nus.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-ontario",
   "metadata": {},
   "source": [
    "#### This code is used for performing machine learning. This code was written form scratch by me with the help of algorithms from python library scikit learn.\n",
    "\n",
    "The code needs user input for the name of the file the data is stored in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-basic",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "\n",
    "* [Importing the Required Libraries](#import)\n",
    "* [Creating a Document to Store the Results](#create)\n",
    "* [Retrieval of the Data](#ret)\n",
    "* [Machine Learning](#ml)\n",
    "* [Model Metrics](#mm)\n",
    "* [Evaluation of the Best Model](#eval)\n",
    "* [Explainable Machine Learning](#expml)\n",
    "    * [Post-hoc Global](#phg)\n",
    "    * [Post-hoc Local](#phl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-immune",
   "metadata": {},
   "source": [
    "### Importing the Required Libraries<a class=\"anchor\" id=\"import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import docx\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "import xgboost\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-financing",
   "metadata": {},
   "source": [
    "### Creating a Document to Store the Results of Machine Learning <a class=\"anchor\" id=\"create\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydoc= docx.Document()\n",
    "mydoc.add_heading(\"Machine Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-munich",
   "metadata": {},
   "source": [
    "### Retrieval of Data <a class=\"anchor\" id=\"ret\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-kidney",
   "metadata": {},
   "source": [
    "Supplementary note: The target feature should be the the last column of the data inputted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=input(\"Filename:\")\n",
    "df= pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the target property and features\n",
    "y= df.iloc[:, -1:]\n",
    "lendf= len(df.columns)\n",
    "x= df.drop(df.columns[lendf-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the models for all the algorithms that are going to be used in Machine Learning\n",
    "clf= RandomForestClassifier()\n",
    "svc= SVC()\n",
    "knn= KNeighborsClassifier()\n",
    "dtc= DecisionTreeClassifier()\n",
    "gnb= GaussianNB()\n",
    "lda= LinearDiscriminantAnalysis()\n",
    "#qda= QuadraticDiscriminantAnalysis()\n",
    "abc= AdaBoostClassifier()\n",
    "gbc= GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-validation",
   "metadata": {},
   "source": [
    "### Machine Learning <a class=\"anchor\" id=\"ml\"></a>\n",
    "\n",
    "Scikit Learn, a machine learning library in Python was used for conducting machinelearning.  A plethora of algorithms which were used to conduct machine learningare grouped in representative categories as seen below.\n",
    "\n",
    "![title](Pictures/ml.png)\n",
    "\n",
    "The taxonomy of arranging the machine learning algorithms into different types is important because it helps us determine which algorithm would be the best for the particular dataset at hand.\n",
    "\n",
    "Decision Tree Algorithm which construct a model of decisions based on actual values of attributes in the data.\n",
    "\n",
    "Bayesian Algorithm These alorgithms apply Bayes' thereom for classification.\n",
    "\n",
    "Clustering Algorithm They are typically organized by the modelling approaches such as centroid-based and hierarchal.\n",
    "\n",
    "Dimensionality Reduction Algorithm. This algorithm seeks and exploits the inherent structure in the data\n",
    "Ensemble Algorithms are models which contain multiple weaker models that are independently trained and whose predictions are combined in some way to make the overall prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def machine_learning(testratio, rangebegin, rangeend, x, y, exploring, particular):\n",
    "    \n",
    "    \n",
    "    results=[]\n",
    "    if (rangebegin==rangeend):\n",
    "        y= np.where(y==rangebegin, 0, 1)\n",
    "    \n",
    "    else:\n",
    "        y= np.where(y>= rangebegin and normalised_y<= rangeend, 0, 1)\n",
    "    \n",
    "    x_classification_train, x_classification_test, y_classification_train, y_classification_test= train_test_split(x, y, test_size= testratio)\n",
    "    allfeatimp=[]\n",
    "    bestmodel=clf\n",
    "    bestaccuracy=0\n",
    "    bestparticular=-1\n",
    "    cm=[]\n",
    "    \n",
    "  \n",
    "    if exploring==1 or particular==0:\n",
    "        mydoc.add_paragraph(\"Random Forest Classifier\")\n",
    "        clf.fit(x_classification_train, y_classification_train)\n",
    "        clf_prediction= clf.predict(x_classification_test)\n",
    "        results.append(accuracy_score(clf_prediction, y_classification_test))\n",
    "        allfeatimp.append(modelmetric(clf_prediction, y_classification_test, x_classification_test, clf, 0, testratio))\n",
    "        if(accuracy_score(clf_prediction, y_classification_test)>bestaccuracy):\n",
    "            bestaccuracy= accuracy_score(clf_prediction, y_classification_test)\n",
    "            bestmodel=clf\n",
    "            bestparticular=0\n",
    "            \n",
    "\n",
    "    if exploring==1 or particular==1:\n",
    "        mydoc.add_paragraph(\"Support Vector Machines\")\n",
    "        svc.fit(x_classification_train, y_classification_train)\n",
    "        SVC_prediction = svc.predict(x_classification_test)\n",
    "        results.append(accuracy_score(SVC_prediction, y_classification_test))\n",
    "        allfeatimp.append(modelmetric(SVC_prediction, y_classification_test, x_classification_test, svc, 1, testratio))\n",
    "        if(accuracy_score(SVC_prediction, y_classification_test)>bestaccuracy):\n",
    "            bestaccuracy= accuracy_score(SVC_prediction, y_classification_test)\n",
    "            bestmodel=svc\n",
    "            bestparticular=1\n",
    " \n",
    "     \n",
    "    \n",
    "    if exploring==1 or particular==2:\n",
    "        mydoc.add_paragraph(\"KNeighbours Classifier\")\n",
    "        knn.fit(x_classification_train, y_classification_train)\n",
    "        KNN_prediction = knn.predict(x_classification_test)\n",
    "        results.append(accuracy_score(KNN_prediction, y_classification_test))\n",
    "        allfeatimp.append(modelmetric(KNN_prediction, y_classification_test, x_classification_test, knn, 2, testratio))\n",
    "        if(accuracy_score(KNN_prediction, y_classification_test)>bestaccuracy):\n",
    "            bestaccuracy= accuracy_score(KNN_prediction, y_classification_test)\n",
    "            bestmodel=knn\n",
    "            bestparticular=2\n",
    "      \n",
    "    \n",
    "    if exploring==1 or particular==3:\n",
    "        mydoc.add_paragraph(\"Decision Tree Classifier\")\n",
    "        dtc.fit(x_classification_train, y_classification_train)\n",
    "        dtc_prediction = dtc.predict(x_classification_test)\n",
    "        results.append(accuracy_score(dtc_prediction, y_classification_test))\n",
    "        allfeatimp.append(modelmetric(dtc_prediction, y_classification_test, x_classification_test, dtc, 3, testratio))\n",
    "        if(accuracy_score(dtc_prediction, y_classification_test)>bestaccuracy):\n",
    "            bestaccuracy= accuracy_score(dtc_prediction, y_classification_test)\n",
    "            bestmodel=dtc\n",
    "            bestparticular=3\n",
    "        \n",
    "    \n",
    "    if exploring==1 or particular==4:\n",
    "        mydoc.add_paragraph(\"Gaussian NB\")\n",
    "        gnb.fit(x_classification_train, y_classification_train)\n",
    "        gnb_prediction = gnb.predict(x_classification_test)\n",
    "        #print(gnb.predict_proba(x_classification_test))\n",
    "        results.append(accuracy_score(gnb_prediction, y_classification_test))\n",
    "        allfeatimp.append(modelmetric(gnb_prediction, y_classification_test, x_classification_test, gnb, 4, testratio))\n",
    "        if(accuracy_score(gnb_prediction, y_classification_test)>bestaccuracy):\n",
    "            bestaccuracy= accuracy_score(gnb_prediction, y_classification_test)\n",
    "            bestmodel= gnb\n",
    "            bestparticular=4\n",
    "        \n",
    "    \n",
    "    if exploring==1 or particular==5:\n",
    "        mydoc.add_paragraph(\"Linear Discriminant Analysis\")\n",
    "        lda.fit(x_classification_train, y_classification_train)\n",
    "        lda_prediction = lda.predict(x_classification_test)\n",
    "        results.append(accuracy_score(lda_prediction, y_classification_test))\n",
    "        allfeatimp.append(modelmetric(lda_prediction, y_classification_test, x_classification_test, lda, 5, testratio))\n",
    "        if(accuracy_score(lda_prediction, y_classification_test)>bestaccuracy):\n",
    "            bestaccuracy= accuracy_score(lda_prediction, y_classification_test)\n",
    "            bestmodel= lda\n",
    "            bestparticular=5\n",
    "            \n",
    "    \"\"\"      \n",
    "    if exploring==1 or particular==6:\n",
    "        mydoc.add_paragraph(\"Quadratic Discriminant Analysis\")\n",
    "        qda.fit(x_classification_train, y_classification_train)\n",
    "        qda_prediction = qda.predict(x_classification_test)\n",
    "        results.append(accuracy_score(qda_prediction, y_classification_test))\n",
    "        allfeatimp.append(modelmetric(prediction, y_classification_test, x_classification_test, qda, 6, testratio))\n",
    "        if(accuracy_score(qda_prediction, y_classification_test)>bestaccuracy):\n",
    "            bestaccuracy= accuarcy_score(qda_prediction, y_classification_test)\n",
    "            bestmodel= qda\n",
    "            bestparticular=6\n",
    "    \"\"\"\n",
    "            \n",
    "    if exploring==1 or particular==7:\n",
    "        mydoc.add_paragraph(\"Ada Boost Classifier\")\n",
    "        abc.fit(x_classification_train, y_classification_train)\n",
    "        abc_prediction = abc.predict(x_classification_test)\n",
    "        results.append(accuracy_score(abc_prediction, y_classification_test))\n",
    "        allfeatimp.append(modelmetric(abc_prediction, y_classification_test, x_classification_test, abc, 7, testratio))\n",
    "        if(accuracy_score(abc_prediction, y_classification_test)>bestaccuracy):\n",
    "            bestaccuracy= accuracy_score(abc_prediction, y_classification_test)\n",
    "            bestmodel= abc\n",
    "            bestparticular=7\n",
    "    \n",
    "    \n",
    "    if exploring==1 or particular==8:\n",
    "        mydoc.add_paragraph(\"Gradient Boost Classifier\")\n",
    "        gbc.fit(x_classification_train, y_classification_train)\n",
    "        gbc_prediction = gbc.predict(x_classification_test)\n",
    "        results.append(accuracy_score(gbc_prediction, y_classification_test))\n",
    "        allfeatimp.append(modelmetric(gbc_prediction, y_classification_test, x_classification_test, gbc, 8, testratio))\n",
    "        if(accuracy_score(gbc_prediction, y_classification_test)>bestaccuracy):\n",
    "            bestaccuracy= accuracy_score(gbc_prediction, y_classification_test)\n",
    "            bestmodel= gbc\n",
    "            bestparticular=8\n",
    "    \n",
    "    return results, bestmodel, bestparticular, bestaccuracy, allfeatimp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-emergency",
   "metadata": {},
   "source": [
    "### Model Metrics <a class=\"anchor\" id=\"mm\"></a>\n",
    "This function computes all the metrics which are needed for the evaluation of the model. For instance, specificty, sensitvity, negative predictive value, precision , confusion matrix, ROC and recall curves and feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestsensitivity=[0, 0, 0]\n",
    "bestspecificity= [0, 0, 0]\n",
    "bestnpv=[0, 0, 0]\n",
    "bestprecision= [0, 0, 0]\n",
    "\n",
    "def modelmetric(prediction, y_test, x_test, model, particular, testratio):\n",
    "    mydoc.add_paragraph(\"Accuracy Score:\")\n",
    "    mydoc.add_paragraph(str(accuracy_score(prediction, y_test)))\n",
    "    mydoc.add_paragraph(\"Confusion Matrix\")\n",
    "    mydoc.add_paragraph(str(confusion_matrix(prediction, y_test)))\n",
    "    \n",
    "    \n",
    "    cm= confusion_matrix(prediction, y_test)\n",
    "    \n",
    "    #print(cm)\n",
    "    #print(prediction.sum())\n",
    "    \n",
    "    \n",
    "  \n",
    "    truepositive= cm[0][0]\n",
    "    falsenegative= cm[0][1]\n",
    "    falsepositive= cm[1][0]\n",
    "    truenegative= cm[1][1]\n",
    "    \n",
    "   \n",
    "\n",
    "    sensitivity= truepositive/(truepositive+falsenegative)\n",
    "    if sensitivity>bestsensitivity[0]:\n",
    "        bestsensitivity[0]= sensitivity\n",
    "        bestsensitivity[1]= particular\n",
    "        bestsensitivity[2]= testratio\n",
    "        \n",
    "    specificity= truenegative/(truenegative+falsepositive)\n",
    "    if specificity>bestspecificity[0]:\n",
    "        bestspecificity[0]= specificity\n",
    "        bestspecificity[1]= particular\n",
    "        bestspecificity[2]= testratio\n",
    "        \n",
    "    npv= truenegative/(truenegative+falsenegative)\n",
    "    if npv>bestnpv[0]:\n",
    "        bestnpv[0]= npv\n",
    "        bestnpv[1]= particular\n",
    "        bestnpv[2]= testratio\n",
    "     \n",
    "    \n",
    "    precision= truepositive/(truepositive+falsepositive)\n",
    "    if precision >bestprecision[0]:\n",
    "        bestprecision[0]= precision\n",
    "        bestprecision[1]= particular\n",
    "        bestprecision[2]= testratio\n",
    "    \n",
    "    mse= mean_squared_error(y_test, prediction)\n",
    "    mse= np.sqrt(mse)\n",
    " \n",
    "    metrics.plot_roc_curve(model, x_test, y_test)\n",
    "    plt.close()\n",
    "    plt.savefig(\"ROCCurve.png\")\n",
    "    mydoc.add_picture(\"ROCCurve.png\")\n",
    "    plot_precision_recall_curve(model, x_test, y_test)\n",
    "    plt.savefig(\"Recall.png\")\n",
    "    mydoc.add_picture(\"Recall.png\")\n",
    "  \n",
    "    \n",
    "    \n",
    "    mydoc.add_paragraph(\"Sensitivity\")\n",
    "    mydoc.add_paragraph(str(sensitivity))\n",
    "    mydoc.add_paragraph(\"Specificty\")\n",
    "    mydoc.add_paragraph(str(specificity))\n",
    "    mydoc.add_paragraph(\"Precision\")\n",
    "    mydoc.add_paragraph(str(precision))\n",
    "    mydoc.add_paragraph(\"Negative Predictive Value\")\n",
    "    mydoc.add_paragraph(str(npv))\n",
    "    mydoc.add_paragraph(\"Mean Squared Error\")\n",
    "    mydoc.add_paragraph(str(mse))\n",
    "    \n",
    "    \n",
    "   \n",
    "    positions=[]\n",
    "    if particular==0 or particular==3 or particular==7 or particular==8:\n",
    "        mydoc.add_paragraph(\"Feature Importances\")\n",
    "        featimp= model.feature_importances_\n",
    "        temp= np.sort(featimp)[::-1]\n",
    "        #print(temp)\n",
    "        for i in range(0, 5):\n",
    "            for j in range(0, len(featimp)):\n",
    "                if temp[i]== featimp[j]:\n",
    "                    positions.append(j)\n",
    "                   \n",
    "        listcolumns= x_test.columns\n",
    "        #print(positions)\n",
    "        #print(listcolumns)\n",
    "        for i in range(5):\n",
    "            mydoc.add_paragraph(listcolumns[positions[i]])\n",
    "        \n",
    "        plt.close()\n",
    "        plt.clf()\n",
    "        pyplot.bar([0, 1, 2, 3, 4], temp[:5])\n",
    "        plt.xticks([0, 1, 2, 3, 4], [listcolumns[positions[0]], listcolumns[positions[1]], listcolumns[positions[2]], listcolumns[positions[3]], listcolumns[positions[4]]], rotation=45)\n",
    "        plt.savefig(\"FeatureImportance.png\", bbox_inches='tight')\n",
    "        mydoc.add_picture(\"FeatureImportance.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "    return positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-steam",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "This evaualted which model and what training ratio performs the best for the given model. It further saves the best model obtained in the folder for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation():\n",
    "    trainingratios= [0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90]\n",
    "    bestmodelactual= 0\n",
    "    bestparticularactual=0\n",
    "    bestaccuracyactual=0\n",
    "    besttrainingratioactual=0\n",
    "    \n",
    "    for i in range(len(trainingratios)):\n",
    "        results, bestmodel, bestparticular, bestaccuracy, allfeatimp= machine_learning(trainingratios[i], 0, 0, x, y, 1, -1)\n",
    "        if bestaccuracyactual< bestaccuracy:\n",
    "            bestaccuracyactual= bestaccuracy\n",
    "            besttrainingratioactual= trainingratios[1]\n",
    "            bestmodelactual= bestmodel\n",
    "            bestparticularactual= bestparticular\n",
    "                     \n",
    "    mydoc.add_heading(\"Best Model\")\n",
    "    machine_learning(besttrainingratioactual, 0, 0, x, y, -1, bestparticular)\n",
    "    mydoc.add_paragraph(\"Best Training Ratio\")\n",
    "    mydoc.add_paragraph(str(besttrainingratioactual))\n",
    "    pickle.dump(bestmodelactual, open('model.pkl','wb'))\n",
    "    model = pickle.load(open('model.pkl','rb'))\n",
    "    \n",
    "    \n",
    "evaluation() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-feature",
   "metadata": {},
   "source": [
    "### Explainable Machine Learning\n",
    "\n",
    "There are different ways of explaining the model at hand. Either the model's interpretability could be achieved by limiting its complexity (intrinsic explainability). If the model is analysed after training that would constitute a post-hoc explainability. If the interpretation was pertaining to an individual prediction it would be a local explanation and a global explanation if it interpreted the entire model.\n",
    "\n",
    "In this project, SHAP or the SHapely Additive Explanantion was used as a global post-hoc approach to explain the models. SHAP is a game theoretic approach which uses the classic Shapley values \\cite{SHAP}. Further LIME or Local Interpretable Model-Agnostic Explanations, were used as a local post-hoc approach to explain a particular instance in the model \\cite{lime}. Since intrinsic models compromise the accuracy if the model, they were avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-processing",
   "metadata": {},
   "source": [
    "### Post Hoc Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_explainability(X, y):\n",
    "    model = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(X, label=y), 100)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    shap.force_plot(explainer.expected_value, shap_values, X)\n",
    "    shap.force_plot(explainer.expected_value, shap_values, X)\n",
    "    shap.summary_plot(shap_values, X) \n",
    "    shap.dependence_plot(\"bandgap\", shap_values, x)#change the feature accordingly\n",
    "    \n",
    "shap_explainability(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to see the force plot\n",
    "\"\"\"\n",
    "model = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(x, label=y), 100)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(x)\n",
    "shap.force_plot(explainer.expected_value, shap_values, x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-sleeve",
   "metadata": {},
   "source": [
    "### Post Hoc Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('model.pkl','rb'))\n",
    "predict_fn_rf = lambda x: model.predict_proba(x).astype(float)\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(x.values, feature_names= x.columns)\n",
    "pos= input(\"Position of Chosen Instance\")\n",
    "pos= int(pos)\n",
    "chosen_instance = x.loc[pos].values\n",
    "exp = explainer.explain_instance(chosen_instance, predict_fn_rf)\n",
    "exp.show_in_notebook(show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to see the threshold computations\n",
    "\n",
    "\n",
    "def threshold_computation(theta, x, y): #binning\n",
    "    \n",
    "    y= df.iloc[:, -1:]\n",
    "    lendf= len(df.columns)\n",
    "    y= np.where((-1*theta<=y) & (y<= theta), 0, 1)\n",
    "    x= df.drop(df.columns[lendf-1], axis=1)\n",
    "    x_classification_train, x_classification_test, y_classification_train, y_classification_test= train_test_split(x, y, test_size= 0.2)\n",
    "    gbc.fit(x_classification_train, y_classification_train)\n",
    "    gbc_prediction = gbc.predict(x_classification_test)\n",
    "    mydoc.add_paragraph(str(accuracy_score(gbc_prediction, y_classification_test)))\n",
    "    cm= confusion_matrix(gbc_prediction, y_classification_test)\n",
    "    \n",
    "    truepositive= cm[0][0]\n",
    "    falsenegative= cm[0][1]\n",
    "    falsepositive= cm[1][0]\n",
    "    truenegative= cm[1][1]\n",
    "    \n",
    "   \n",
    "\n",
    "    sensitivity= truepositive/(truepositive+falsenegative)\n",
    "    \n",
    "    specificity= truenegative/(truenegative+falsepositive)\n",
    "    \n",
    "    npv= truenegative/(truenegative+falsenegative)\n",
    "  \n",
    "    \n",
    "    precision= truepositive/(truepositive+falsepositive)\n",
    "    \n",
    "    mse= mean_squared_error(y_classification_test, gbc_prediction)\n",
    "    mse= np.sqrt(mse)\n",
    "    mydoc.add_paragraph(\"Sensitivity\")\n",
    "    mydoc.add_paragraph(str(sensitivity))\n",
    "    mydoc.add_paragraph(\"Specificty\")\n",
    "    mydoc.add_paragraph(str(specificity))\n",
    "    mydoc.add_paragraph(\"Precision\")\n",
    "    mydoc.add_paragraph(str(precision))\n",
    "    mydoc.add_paragraph(\"Negative Predictive Value\")\n",
    "    mydoc.add_paragraph(str(npv))\n",
    "    mydoc.add_paragraph(\"Mean Squared Error\")\n",
    "    mydoc.add_paragraph(str(mse))\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "theta= [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5]\n",
    "for i in range(len(theta)):\n",
    "    mydoc.add_paragraph(\"Theta\")\n",
    "    mydoc.add_paragraph(str(theta[i]))\n",
    "    threshold_computation(theta[i], x, y)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydoc.add_heading(\"End of Machine Learning\")\n",
    "mydoc.save(\"MachineLearning1.docx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
